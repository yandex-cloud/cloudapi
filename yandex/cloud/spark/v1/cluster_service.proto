syntax = "proto3";

package yandex.cloud.spark.v1;

import "google/protobuf/field_mask.proto";
import "yandex/cloud/spark/v1/cluster.proto";
import "yandex/cloud/spark/v1/maintenance.proto";
import "yandex/cloud/operation/operation.proto";
import "yandex/cloud/validation.proto";
import "yandex/cloud/api/operation.proto";

option go_package = "github.com/yandex-cloud/go-genproto/yandex/cloud/spark/v1;spark";
option java_package = "yandex.cloud.api.spark.v1";

// A set of methods for managing Spark clusters.
service ClusterService {
  // Returns the specified Spark cluster.
  rpc Get (GetClusterRequest) returns (Cluster) {
  }

  // Retrieves a list of Spark clusters.
  rpc List (ListClustersRequest) returns (ListClustersResponse) {
  }

  // Creates a Spark cluster.
  rpc Create (CreateClusterRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "CreateClusterMetadata"
      response: "Cluster"
    };
  }

  // Updates configuration of the specified Spark cluster.
  rpc Update (UpdateClusterRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "UpdateClusterMetadata"
      response: "Cluster"
    };
  }

  // Deletes the specified Spark cluster.
  rpc Delete (DeleteClusterRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "DeleteClusterMetadata"
      response: "google.protobuf.Empty"
    };
  }

  // Start the specified Spark cluster.
  rpc Start (StartClusterRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "StartClusterMetadata"
      response: "Cluster"
    };
  }

  // Stops the specified Spark cluster
  rpc Stop (StopClusterRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "StopClusterMetadata"
      response: "Cluster"
    };
  }

  rpc ListOperations (ListClusterOperationsRequest) returns (ListClusterOperationsResponse) {
  }
}

message GetClusterRequest {
  // ID of the Spark cluster to return.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];
}

message ListClustersRequest {
  // ID of the folder to list Spark clusters in.
  string folder_id = 1 [(required) = true, (length) = "<=50"];

  // The maximum number of results per page that should be returned. If the number of available
  // results is larger than `page_size`, the service returns a `next_page_token` that can be used
  // to get the next page of results in subsequent ListClusters requests.
  // Acceptable values are 0 to 1000, inclusive. Default value: 100.
  int64 page_size = 2 [(value) = "<=1000"];

  // Page token. Set `page_token` to the `next_page_token` returned by a previous ListClusters
  // request to get the next page of results.
  string page_token = 3 [(length) = "<=200"];

  // String that describes a display filter.
  string filter = 4 [(length) = "<=1000"];
}

message ListClustersResponse {
  // Requested list of Spark clusters.
  repeated Cluster clusters = 1;

  // This token allows you to get the next page of results for ListClusters requests,
  // if the number of results is larger than `page_size` specified in the request.
  // To get the next page, specify the value of `next_page_token` as a value for
  // the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
  // requests will have their own `next_page_token` to continue paging through the results.
  string next_page_token = 2 [(length) = "<=200"];
}

message CreateClusterRequest {
  // ID of the folder to create Spark cluster in.
  string folder_id = 1 [(required) = true, (length) = "<=50"];

  // Name of the Spark cluster. The name must be unique within the folder.
  string name = 2 [(required) = true, (length) = "<=63", (pattern) = "^[a-z][-a-z0-9]{1,61}[a-z0-9]$"];

  // Description of the Spark cluster. 0-256 characters long.
  string description = 3 [(length) = "<=256"];

  map<string, string> labels = 4 [(yandex.cloud.size) = "<=64", (length) = "<=63", (pattern) = "[-_0-9a-z]*", (map_key).length = "1-63", (map_key).pattern = "[a-z][-_0-9a-z]*"];

  ClusterConfig config = 5 [(required) = true];

  NetworkConfig network = 6 [(required) = true];

  // Deletion Protection inhibits deletion of the cluster
  bool deletion_protection = 7;

  // Service account that will be used to access YC resources
  string service_account_id = 8 [(required) = true, (length) = "<=50"];

  // Cloud logging configuration
  LoggingConfig logging = 9;

  // Window of maintenance operations.
  MaintenanceWindow maintenance_window = 10;
}

message CreateClusterMetadata {
  // ID of the creating Spark cluster.
  string cluster_id = 1 [(required) = true];
}

message UpdateClusterRequest {
  // ID of the Spark cluster.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];

  google.protobuf.FieldMask update_mask = 2;

  string name = 3 [(pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];

  // Description of the Spark cluster. 0-256 characters long.
  string description = 4 [(length) = "<=256"];

  map<string, string> labels = 5 [(yandex.cloud.size) = "<=64", (length) = "<=63", (pattern) = "[-_0-9a-z]*", (map_key).length = "1-63", (map_key).pattern = "[a-z][-_0-9a-z]*"];

  UpdateClusterConfigSpec config_spec = 6;

  UpdateNetworkConfigSpec network_spec = 7;

  // Deletion Protection inhibits deletion of the cluster
  bool deletion_protection = 8;

  // Service account used to access Cloud resources.
  string service_account_id = 9 [(length) = "<=50"];

  // Cloud logging configuration
  LoggingConfig logging = 10;

  // Window of maintenance operations.
  MaintenanceWindow maintenance_window = 11;
}

message UpdateClusterMetadata {
  // ID of the updating Spark cluster.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];
}

message DeleteClusterRequest {
  // ID of the Spark cluster to delete.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];
}

message DeleteClusterMetadata {
  // ID of the deleting Spark cluster.
  string cluster_id = 1 [(required) = true];
}

message StartClusterRequest {
  // ID of the Spark cluster that is being started.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];
}

message StartClusterMetadata {
  // ID of the Spark cluster.
  string cluster_id = 1;
}

message StopClusterRequest {
  // ID of the Spark cluster that is being stopped.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];
}

message StopClusterMetadata {
  // ID of the Spark cluster.
  string cluster_id = 1;
}

message ListClusterOperationsRequest {
  // ID of the Spark cluster.
  string cluster_id = 1 [(required) = true, (length) = "<=50"];

  // The maximum number of results per page that should be returned. If the number of available
  // results is larger than `page_size`, the service returns a `next_page_token` that can be used
  // to get the next page of results in subsequent ListOperations requests.
  // Acceptable values are 0 to 1000, inclusive. Default value: 100.
  int64 page_size = 2 [(value) = "<=1000"];

  // Page token. Set `page_token` to the `next_page_token` returned by a previous ListOperations
  // request to get the next page of results.
  string page_token = 3 [(length) = "<=200"];
}

message ListClusterOperationsResponse {
  repeated operation.Operation operations = 1;

  // This token allows you to get the next page of results for ListOperations requests,
  // if the number of results is larger than `page_size` specified in the request.
  // To get the next page, specify the value of `next_page_token` as a value for
  // the `page_token` parameter in the next ListOperations request. Subsequent ListOperations
  // requests will have their own `next_page_token` to continue paging through the results.
  string next_page_token = 2 [(length) = "<=200"];
}
